# docker-compose.yml (in project root: dzinza-python/)
x-default-logging: &logging
  driver: "json-file"
  options:
    max-size: "5m"
    max-file: "2"
    tag: "{{.Name}}"
services:
  redis:
    image: redis:latest
    container_name: dzinza-redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  dbservice:
    image: postgres:15-alpine
    container_name: dzinza-db
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - INITIAL_ADMIN_PASSWORD=${INITIAL_ADMIN_PASSWORD}
    volumes:
      - db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $POSTGRES_USER -d $POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: dzinza-backend
    ports:
      - "8090:8090"
    depends_on:
      dbservice:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://backend:8090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@dbservice:5432/${POSTGRES_DB}
      - INITIAL_ADMIN_PASSWORD=${INITIAL_ADMIN_PASSWORD}
      - REDIS_URL=redis://redis:6379/0
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318  # Changed from localhost to service name
    restart: unless-stopped
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: dzinza-frontend
    ports:
      - "5173:80"
    depends_on:
      backend:
        condition: service_started
    restart: unless-stopped

  # ********************
  # Telemetry Components
  # ********************
  # Jaeger
  jaeger:
    image: jaegertracing/all-in-one:1.66.0
    container_name: jaeger
    command:
      - "--memory.max-traces=25000"
      - "--query.base-path=/jaeger/ui"
      - "--prometheus.server-url=http://prometheus:9090"
      - "--prometheus.query.normalize-calls=true"
      - "--prometheus.query.normalize-duration=true"
    deploy:
      resources:
        limits:
          memory: 1200M
    restart: unless-stopped
    ports:
      - "16686"        # Jaeger UI
      - "4317"
    environment:
      - METRICS_STORAGE_TYPE=prometheus
    logging: *logging

  # Grafana
  grafana:
    image: grafana/grafana:11.5.2
    container_name: grafana
    deploy:
      resources:
        limits:
          memory: 120M
    restart: unless-stopped
    environment:
      - "GF_INSTALL_PLUGINS=grafana-opensearch-datasource"
    volumes:
      - ./otel-config/grafana.ini:/etc/grafana/grafana.ini
      - ./otel-config/provisioning/:/etc/grafana/provisioning/
    ports:
      - "3000"
    logging: *logging

  # OpenTelemetry Collector
  otel-collector:
    image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.120.0
    container_name: otel-collector
    deploy:
      resources:
        limits:
          memory: 200M
    restart: unless-stopped
    command: [ "--config=/etc/otelcol-config.yml", "--config=/etc/otelcol-config-extras.yml" ]
    user: 0:0
    volumes:
      - ./:/hostfs:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./otel-config/otelcol-config.yml:/etc/otelcol-config.yml
      - ./otel-config/otelcol-config-extras.yml:/etc/otelcol-config-extras.yml
    ports:
      - "4317"
      - "4318"
    depends_on:
      jaeger:
        condition: service_started
      opensearch:
        condition: service_healthy
    logging: *logging
    environment:
      - ENVOY_PORT
      - HOST_FILESYSTEM
      - OTEL_COLLECTOR_HOST
      - OTEL_COLLECTOR_PORT_GRPC
      - OTEL_COLLECTOR_PORT_HTTP
      - GOMEMLIMIT=160MiB

  # Prometheus
  prometheus:
    image: quay.io/prometheus/prometheus:v3.2.0
    container_name: prometheus
    command:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --storage.tsdb.retention.time=1h
      - --config.file=/etc/prometheus/prometheus-config.yaml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
      - --web.route-prefix=/
      - --web.enable-otlp-receiver
      - --enable-feature=exemplar-storage
    volumes:
      - ./otel-config/prometheus-config.yaml:/etc/prometheus/prometheus-config.yaml
    deploy:
      resources:
        limits:
          memory: 300M
    restart: unless-stopped
    ports:
      - "9090:9090"
    logging: *logging

  # OpenSearch
  opensearch:
    image: opensearchproject/opensearch:2.19.0
    container_name: opensearch
    deploy:
      resources:
        limits:
          memory: 1.1G
    restart: unless-stopped
    environment:
      - cluster.name=demo-cluster
      - node.name=demo-node
      - bootstrap.memory_lock=true
      - discovery.type=single-node
      - OPENSEARCH_JAVA_OPTS=-Xms300m -Xmx300m
      - DISABLE_INSTALL_DEMO_CONFIG=true
      - DISABLE_SECURITY_PLUGIN=true
      # Workaround on OSX for https://bugs.openjdk.org/browse/JDK-8345296
      - _JAVA_OPTIONS
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    ports:
      - "9200"
    healthcheck:
      test: curl -s http://localhost:9200/_cluster/health | grep -E '"status":"(green|yellow)"'
      start_period: 10s
      interval: 5s
      timeout: 10s
      retries: 10
    logging: *logging

volumes:
  db_data:
    driver: local